{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "from scipy.stats import skew, boxcox\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import ast\n",
    "import re\n",
    "import yaml\n",
    "import json\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import eli5\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings  \n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 23 columns):\n",
      "id                       3000 non-null int64\n",
      "belongs_to_collection    604 non-null object\n",
      "budget                   3000 non-null int64\n",
      "genres                   2993 non-null object\n",
      "homepage                 946 non-null object\n",
      "imdb_id                  3000 non-null object\n",
      "original_language        3000 non-null object\n",
      "original_title           3000 non-null object\n",
      "overview                 2992 non-null object\n",
      "popularity               3000 non-null float64\n",
      "poster_path              2999 non-null object\n",
      "production_companies     2844 non-null object\n",
      "production_countries     2945 non-null object\n",
      "release_date             3000 non-null object\n",
      "runtime                  2998 non-null float64\n",
      "spoken_languages         2980 non-null object\n",
      "status                   3000 non-null object\n",
      "tagline                  2403 non-null object\n",
      "title                    3000 non-null object\n",
      "Keywords                 2724 non-null object\n",
      "cast                     2987 non-null object\n",
      "crew                     2984 non-null object\n",
      "revenue                  3000 non-null int64\n",
      "dtypes: float64(2), int64(3), object(18)\n",
      "memory usage: 539.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4398 entries, 0 to 4397\n",
      "Data columns (total 22 columns):\n",
      "id                       4398 non-null int64\n",
      "belongs_to_collection    877 non-null object\n",
      "budget                   4398 non-null int64\n",
      "genres                   4382 non-null object\n",
      "homepage                 1420 non-null object\n",
      "imdb_id                  4398 non-null object\n",
      "original_language        4398 non-null object\n",
      "original_title           4398 non-null object\n",
      "overview                 4384 non-null object\n",
      "popularity               4398 non-null float64\n",
      "poster_path              4397 non-null object\n",
      "production_companies     4140 non-null object\n",
      "production_countries     4296 non-null object\n",
      "release_date             4397 non-null object\n",
      "runtime                  4394 non-null float64\n",
      "spoken_languages         4356 non-null object\n",
      "status                   4396 non-null object\n",
      "tagline                  3535 non-null object\n",
      "title                    4395 non-null object\n",
      "Keywords                 4005 non-null object\n",
      "cast                     4385 non-null object\n",
      "crew                     4376 non-null object\n",
      "dtypes: float64(2), int64(2), object(18)\n",
      "memory usage: 756.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\n",
    "test = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\n",
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          0\n",
       "belongs_to_collection    2396\n",
       "budget                      0\n",
       "genres                      7\n",
       "homepage                 2054\n",
       "imdb_id                     0\n",
       "original_language           0\n",
       "original_title              0\n",
       "overview                    8\n",
       "popularity                  0\n",
       "poster_path                 1\n",
       "production_companies      156\n",
       "production_countries       55\n",
       "release_date                0\n",
       "runtime                     2\n",
       "spoken_languages           20\n",
       "status                      0\n",
       "tagline                   597\n",
       "title                       0\n",
       "Keywords                  276\n",
       "cast                       13\n",
       "crew                       16\n",
       "revenue                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          0\n",
       "belongs_to_collection    3521\n",
       "budget                      0\n",
       "genres                     16\n",
       "homepage                 2978\n",
       "imdb_id                     0\n",
       "original_language           0\n",
       "original_title              0\n",
       "overview                   14\n",
       "popularity                  0\n",
       "poster_path                 1\n",
       "production_companies      258\n",
       "production_countries      102\n",
       "release_date                1\n",
       "runtime                     4\n",
       "spoken_languages           42\n",
       "status                      2\n",
       "tagline                   863\n",
       "title                       3\n",
       "Keywords                  393\n",
       "cast                       13\n",
       "crew                       22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct some budgets and revenues as \"0\" in train and test data by checking with IMBb and Wikipedia.\n",
    "train.loc[train['id'] == 16,'revenue'] = 192864         \n",
    "train.loc[train['id'] == 90,'budget'] = 30000000                  \n",
    "train.loc[train['id'] == 118,'budget'] = 60000000       \n",
    "train.loc[train['id'] == 149,'budget'] = 18000000       \n",
    "train.loc[train['id'] == 313,'revenue'] = 12000000       \n",
    "train.loc[train['id'] == 451,'revenue'] = 12000000      \n",
    "train.loc[train['id'] == 464,'budget'] = 20000000       \n",
    "train.loc[train['id'] == 470,'budget'] = 13000000       \n",
    "train.loc[train['id'] == 513,'budget'] = 930000         \n",
    "train.loc[train['id'] == 797,'budget'] = 8000000        \n",
    "train.loc[train['id'] == 819,'budget'] = 90000000       \n",
    "train.loc[train['id'] == 850,'budget'] = 90000000       \n",
    "train.loc[train['id'] == 1007,'budget'] = 2              \n",
    "train.loc[train['id'] == 1112,'budget'] = 7500000       \n",
    "train.loc[train['id'] == 1131,'budget'] = 4300000        \n",
    "train.loc[train['id'] == 1359,'budget'] = 10000000       \n",
    "train.loc[train['id'] == 1542,'budget'] = 1             \n",
    "train.loc[train['id'] == 1570,'budget'] = 15800000       \n",
    "train.loc[train['id'] == 1571,'budget'] = 4000000        \n",
    "train.loc[train['id'] == 1714,'budget'] = 46000000       \n",
    "train.loc[train['id'] == 1721,'budget'] = 17500000       \n",
    "train.loc[train['id'] == 1865,'revenue'] = 25000000      \n",
    "train.loc[train['id'] == 1885,'budget'] = 12             \n",
    "train.loc[train['id'] == 2091,'budget'] = 10             \n",
    "train.loc[train['id'] == 2268,'budget'] = 17500000       \n",
    "train.loc[train['id'] == 2491,'budget'] = 6              \n",
    "train.loc[train['id'] == 2602,'budget'] = 31000000       \n",
    "train.loc[train['id'] == 2612,'budget'] = 15000000       \n",
    "train.loc[train['id'] == 2696,'budget'] = 10000000      \n",
    "train.loc[train['id'] == 2801,'budget'] = 10000000       \n",
    "train.loc[train['id'] == 335,'budget'] = 2 \n",
    "train.loc[train['id'] == 348,'budget'] = 12\n",
    "train.loc[train['id'] == 470,'budget'] = 13000000 \n",
    "train.loc[train['id'] == 513,'budget'] = 1100000\n",
    "train.loc[train['id'] == 640,'budget'] = 6 \n",
    "train.loc[train['id'] == 696,'budget'] = 1\n",
    "train.loc[train['id'] == 797,'budget'] = 8000000 \n",
    "train.loc[train['id'] == 850,'budget'] = 1500000\n",
    "train.loc[train['id'] == 1199,'budget'] = 5 \n",
    "train.loc[train['id'] == 1282,'budget'] = 9              \n",
    "train.loc[train['id'] == 1347,'budget'] = 1\n",
    "train.loc[train['id'] == 1755,'budget'] = 2\n",
    "train.loc[train['id'] == 1801,'budget'] = 5\n",
    "train.loc[train['id'] == 1918,'budget'] = 592 \n",
    "train.loc[train['id'] == 2033,'budget'] = 4\n",
    "train.loc[train['id'] == 2118,'budget'] = 344 \n",
    "train.loc[train['id'] == 2252,'budget'] = 130\n",
    "train.loc[train['id'] == 2256,'budget'] = 1 \n",
    "train.loc[train['id'] == 2696,'budget'] = 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['id'] == 3033,'budget'] = 250 \n",
    "test.loc[test['id'] == 3051,'budget'] = 50\n",
    "test.loc[test['id'] == 3084,'budget'] = 337\n",
    "test.loc[test['id'] == 3224,'budget'] = 4  \n",
    "test.loc[test['id'] == 3594,'budget'] = 25  \n",
    "test.loc[test['id'] == 3619,'budget'] = 500  \n",
    "test.loc[test['id'] == 3831,'budget'] = 3  \n",
    "test.loc[test['id'] == 3935,'budget'] = 500  \n",
    "test.loc[test['id'] == 4049,'budget'] = 995946 \n",
    "test.loc[test['id'] == 4424,'budget'] = 3  \n",
    "test.loc[test['id'] == 4460,'budget'] = 8  \n",
    "test.loc[test['id'] == 4555,'budget'] = 1200000 \n",
    "test.loc[test['id'] == 4624,'budget'] = 30 \n",
    "test.loc[test['id'] == 4645,'budget'] = 500 \n",
    "test.loc[test['id'] == 4709,'budget'] = 450 \n",
    "test.loc[test['id'] == 4839,'budget'] = 7\n",
    "test.loc[test['id'] == 3125,'budget'] = 25 \n",
    "test.loc[test['id'] == 3142,'budget'] = 1\n",
    "test.loc[test['id'] == 3201,'budget'] = 450\n",
    "test.loc[test['id'] == 3222,'budget'] = 6\n",
    "test.loc[test['id'] == 3545,'budget'] = 38\n",
    "test.loc[test['id'] == 3670,'budget'] = 18\n",
    "test.loc[test['id'] == 3792,'budget'] = 19\n",
    "test.loc[test['id'] == 3881,'budget'] = 7\n",
    "test.loc[test['id'] == 3969,'budget'] = 400\n",
    "test.loc[test['id'] == 4196,'budget'] = 6\n",
    "test.loc[test['id'] == 4221,'budget'] = 11\n",
    "test.loc[test['id'] == 4222,'budget'] = 500\n",
    "test.loc[test['id'] == 4285,'budget'] = 11\n",
    "test.loc[test['id'] == 4319,'budget'] = 1\n",
    "test.loc[test['id'] == 4639,'budget'] = 10\n",
    "test.loc[test['id'] == 4719,'budget'] = 45\n",
    "test.loc[test['id'] == 4822,'budget'] = 22\n",
    "test.loc[test['id'] == 4829,'budget'] = 20\n",
    "test.loc[test['id'] == 4969,'budget'] = 20\n",
    "test.loc[test['id'] == 5021,'budget'] = 40 \n",
    "test.loc[test['id'] == 5035,'budget'] = 1 \n",
    "test.loc[test['id'] == 5063,'budget'] = 14 \n",
    "test.loc[test['id'] == 5119,'budget'] = 2 \n",
    "test.loc[test['id'] == 5214,'budget'] = 30 \n",
    "test.loc[test['id'] == 5221,'budget'] = 50 \n",
    "test.loc[test['id'] == 4903,'budget'] = 15\n",
    "test.loc[test['id'] == 4983,'budget'] = 3\n",
    "test.loc[test['id'] == 5102,'budget'] = 28\n",
    "test.loc[test['id'] == 5217,'budget'] = 75\n",
    "test.loc[test['id'] == 5224,'budget'] = 3 \n",
    "test.loc[test['id'] == 5469,'budget'] = 20 \n",
    "test.loc[test['id'] == 5840,'budget'] = 1 \n",
    "test.loc[test['id'] == 5960,'budget'] = 30\n",
    "test.loc[test['id'] == 6506,'budget'] = 11 \n",
    "test.loc[test['id'] == 6553,'budget'] = 280\n",
    "test.loc[test['id'] == 6561,'budget'] = 7\n",
    "test.loc[test['id'] == 6582,'budget'] = 218\n",
    "test.loc[test['id'] == 6638,'budget'] = 5\n",
    "test.loc[test['id'] == 6749,'budget'] = 8 \n",
    "test.loc[test['id'] == 6759,'budget'] = 50 \n",
    "test.loc[test['id'] == 6856,'budget'] = 10\n",
    "test.loc[test['id'] == 6858,'budget'] =  100\n",
    "test.loc[test['id'] == 6876,'budget'] =  250\n",
    "test.loc[test['id'] == 6972,'budget'] = 1\n",
    "test.loc[test['id'] == 7079,'budget'] = 8000000\n",
    "test.loc[test['id'] == 7150,'budget'] = 118\n",
    "test.loc[test['id'] == 6506,'budget'] = 118\n",
    "test.loc[test['id'] == 7225,'budget'] = 6\n",
    "test.loc[test['id'] == 7231,'budget'] = 85\n",
    "test.loc[test['id'] == 5222,'budget'] = 5\n",
    "test.loc[test['id'] == 5322,'budget'] = 90\n",
    "test.loc[test['id'] == 5350,'budget'] = 70\n",
    "test.loc[test['id'] == 5378,'budget'] = 10\n",
    "test.loc[test['id'] == 5545,'budget'] = 80\n",
    "test.loc[test['id'] == 5810,'budget'] = 8\n",
    "test.loc[test['id'] == 5926,'budget'] = 300\n",
    "test.loc[test['id'] == 5927,'budget'] = 4\n",
    "test.loc[test['id'] == 5986,'budget'] = 1\n",
    "test.loc[test['id'] == 6053,'budget'] = 20\n",
    "test.loc[test['id'] == 6104,'budget'] = 1\n",
    "test.loc[test['id'] == 6130,'budget'] = 30\n",
    "test.loc[test['id'] == 6301,'budget'] = 150\n",
    "test.loc[test['id'] == 6276,'budget'] = 100\n",
    "test.loc[test['id'] == 6473,'budget'] = 100\n",
    "test.loc[test['id'] == 6842,'budget'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge external data\n",
    "# External data resource: themoviedb.org\n",
    "train = pd.merge(train, pd.read_csv('../input/tmdb-competition-additional-features/TrainAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n",
    "test = pd.merge(test, pd.read_csv('../input/tmdb-competition-additional-features/TestAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n",
    "\n",
    "additionalTrainData = pd.read_csv('../input/tmdb-box-office-prediction-more-training-data/additionalTrainData.csv')\n",
    "additionalTrainData['release_date'] = additionalTrainData['release_date'].astype('str')\n",
    "additionalTrainData['release_date'] = additionalTrainData['release_date'].str.replace('-', '/')\n",
    "train = pd.concat([train, additionalTrainData])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Release Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2/20/15\n",
       "1       8/6/04\n",
       "2     10/10/14\n",
       "3       3/9/12\n",
       "4       2/5/09\n",
       "5       8/6/87\n",
       "6      8/30/12\n",
       "7      1/15/04\n",
       "8      2/16/96\n",
       "9      4/16/03\n",
       "10    11/21/76\n",
       "11     7/10/87\n",
       "12     9/15/99\n",
       "13      3/4/05\n",
       "14     6/20/02\n",
       "15     10/6/10\n",
       "16      8/4/05\n",
       "17    12/25/13\n",
       "18      2/2/11\n",
       "19      8/2/05\n",
       "Name: release_date, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#release date\n",
    "train['release_date'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #release date reform\n",
    "\n",
    "# train['release_date'] = pd.to_datetime(train['release_date'])\n",
    "# train['release_year'] = train['release_date'].dt.year\n",
    "# train['release_month'] = train['release_date'].dt.month\n",
    "# train['release_day'] = train['release_day'].dt.day\n",
    "# #train.drop(columns='release_date',inplace=True)\n",
    "\n",
    "# test['release_date'] = pd.to_datetime(test['release_date'])\n",
    "# test['release_year'] = test['release_date'].dt.year\n",
    "# test['release_month'] = test['release_date'].dt.month\n",
    "# test['release_day'] = test['release_day'].dt.day\n",
    "# #test.drop(columns='release_date',inplace=True)\n",
    "\n",
    "def date_reform(df):\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "    df['release_year'] = df['release_date'].dt.year\n",
    "    df['release_month'] = df['release_date'].dt.month\n",
    "    df['release_day'] = df['release_date'].dt.day\n",
    "    df['release_dayofweek'] = df['release_date'].dt.dayofweek\n",
    "    df['release_quarter'] = df['release_date'].dt.quarter\n",
    "    return df\n",
    "\n",
    "train = date_reform(train)\n",
    "test = date_reform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2015\n",
       "1    2004\n",
       "2    2014\n",
       "3    2012\n",
       "4    2009\n",
       "Name: release_year, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['release_year'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revise years which are over 2019 or only with two digits\n",
    "def revise_years(df):\n",
    "    df.loc[ (df['release_year'] <= 19) & (df['release_year'] < 100), \"release_year\"] += 2000\n",
    "    df.loc[ (df['release_year'] > 19)  & (df['release_year'] < 100), \"release_year\"] += 1900\n",
    "\n",
    "#train = revise_years(train)\n",
    "#test = revise_years(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Keywords                 2277\n",
       "belongs_to_collection    4397\n",
       "budget                      0\n",
       "cast                     2014\n",
       "crew                     2017\n",
       "genres                   2008\n",
       "homepage                 4055\n",
       "id                       2001\n",
       "imdb_id                   131\n",
       "original_language           0\n",
       "original_title              0\n",
       "overview                  115\n",
       "popularity                  0\n",
       "popularity2              2119\n",
       "poster_path              2002\n",
       "production_companies     2157\n",
       "production_countries     2056\n",
       "rating                    118\n",
       "release_date                0\n",
       "revenue                     0\n",
       "runtime                   108\n",
       "spoken_languages         2021\n",
       "status                   2001\n",
       "tagline                  1574\n",
       "title                       0\n",
       "totalVotes                118\n",
       "release_year                0\n",
       "release_month               0\n",
       "release_day                 0\n",
       "release_dayofweek           0\n",
       "release_quarter             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()\n",
    "#There is no missing values in 'release_year',release month, release_day, release_dayofweek, release_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Budget for inflation\\ndef budget_reform(df):\\n    df['originalBudget'] = df['budget']\\n    df['inflationBudget'] = df['budget'] + df['budget']*1.8/100*(2018-df['release_year']) #Inflation simple formula\\n    df['budget'] = np.log1p(df['budget'])\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Budget for inflation\n",
    "def budget_reform(df):\n",
    "    df['originalBudget'] = df['budget']\n",
    "    df['inflationBudget'] = df['budget'] + df['budget']*1.8/100*(2018-df['release_year']) #Inflation simple formula\n",
    "    df['budget'] = np.log1p(df['budget'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(df):\n",
    "    global json_cols\n",
    "    global train_dict\n",
    "    \n",
    "    rating_na = df.groupby([\"release_year\",\"original_language\"])['rating'].mean().reset_index()\n",
    "    df[df.rating.isna()]['rating'] = df.merge(rating_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
    "    vote_count_na = df.groupby([\"release_year\",\"original_language\"])['totalVotes'].mean().reset_index()\n",
    "    df[df.totalVotes.isna()]['totalVotes'] = df.merge(vote_count_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
    "\n",
    "    df['weightedRating'] = ( df['rating']*df['totalVotes'] + 6.367 * 1000 ) / ( df['totalVotes'] + 1000 )\n",
    "    \n",
    "    df['originalBudget'] = df['budget']\n",
    "    df['inflationBudget'] = df['budget'] + df['budget']*1.8/100*(2018-df['release_year']) #Inflation simple formula\n",
    "    df['budget'] = np.log1p(df['budget']) \n",
    "    \n",
    "    df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "    df['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "    df['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "    df['_collection_name'] = df['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(df['_collection_name'].fillna('')))\n",
    "    df['_collection_name'] = le.transform(df['_collection_name'].fillna('').astype(str))\n",
    "    df['_num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
    "    df['_num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n",
    "\n",
    "    \n",
    "    \n",
    "    df['_popularity_mean_year'] = df['popularity'] / df.groupby(\"release_year\")[\"popularity\"].transform('mean')\n",
    "    df['_budget_runtime_ratio'] = df['budget']/df['runtime'] \n",
    "    df['_budget_popularity_ratio'] = df['budget']/df['popularity']\n",
    "    df['_budget_year_ratio'] = df['budget']/(df['release_year']*df['release_year'])\n",
    "    df['_releaseYear_popularity_ratio'] = df['release_year']/df['popularity']\n",
    "    df['_releaseYear_popularity_ratio2'] = df['popularity']/df['release_year']\n",
    "\n",
    "    df['_popularity_totalVotes_ratio'] = df['totalVotes']/df['popularity']\n",
    "    df['_rating_popularity_ratio'] = df['rating']/df['popularity']\n",
    "    df['_rating_totalVotes_ratio'] = df['totalVotes']/df['rating']\n",
    "    df['_totalVotes_releaseYear_ratio'] = df['totalVotes']/df['release_year']\n",
    "    df['_budget_rating_ratio'] = df['budget']/df['rating']\n",
    "    df['_runtime_rating_ratio'] = df['runtime']/df['rating']\n",
    "    df['_budget_totalVotes_ratio'] = df['budget']/df['totalVotes']\n",
    "    \n",
    "    df['has_homepage'] = 1\n",
    "    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 0\n",
    "    \n",
    "    df['isbelongs_to_collectionNA'] = 0\n",
    "    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n",
    "    \n",
    "    df['isTaglineNA'] = 0\n",
    "    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n",
    "\n",
    "    df['isOriginalLanguageEng'] = 0 \n",
    "    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n",
    "    \n",
    "    df['isTitleDifferent'] = 1\n",
    "    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n",
    "\n",
    "    df['isMovieReleased'] = 1\n",
    "    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n",
    "\n",
    "    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n",
    "    \n",
    "    df['original_title_letter_count'] = df['original_title'].str.len() \n",
    "    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n",
    "\n",
    "\n",
    "    df['title_word_count'] = df['title'].str.split().str.len()\n",
    "    df['overview_word_count'] = df['overview'].str.split().str.len()\n",
    "    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n",
    "    \n",
    "    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n",
    "    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n",
    "    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n",
    "    df['crew_count'] = df['crew'].apply(lambda x : len(x))\n",
    "    \n",
    "\n",
    "    df['meanruntimeByYear'] = df.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n",
    "    df['meanPopularityByYear'] = df.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\n",
    "    df['meanBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('mean')\n",
    "    df['meantotalVotesByYear'] = df.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\n",
    "    df['meanTotalVotesByRating'] = df.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n",
    "    df['medianBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('median')\n",
    "\n",
    "    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n",
    "        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n",
    "        temp = df[col].str.get_dummies(sep=',')\n",
    "        df = pd.concat([df, temp], axis=1, sort=False)\n",
    "    df.drop(['genres_etc'], axis = 1, inplace = True)\n",
    "    \n",
    "    df = df.drop(['id', 'revenue','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n",
    "    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n",
    "    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n",
    "    ],axis=1)\n",
    "    \n",
    "    df.fillna(value=0.0, inplace = True) \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:00<00:01,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Keywords', 'belongs_to_collection', 'budget', 'cast', 'crew', 'genres',\n",
      "       'homepage', 'id', 'imdb_id', 'original_language', 'original_title',\n",
      "       'overview', 'popularity', 'popularity2', 'poster_path',\n",
      "       'production_companies', 'production_countries', 'rating',\n",
      "       'release_date', 'revenue', 'runtime', 'spoken_languages', 'status',\n",
      "       'tagline', 'title', 'totalVotes', 'release_year', 'release_month',\n",
      "       'release_day', 'release_dayofweek', 'release_quarter'],\n",
      "      dtype='object')\n",
      "(5001, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(train.shape)\n",
    "train['revenue'] = np.log1p(train['revenue'])\n",
    "y = train['revenue'].values\n",
    "\n",
    "json_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n",
    "\n",
    "def get_dictionary(s):\n",
    "    try:\n",
    "        d = eval(s)\n",
    "    except:\n",
    "        d = {}\n",
    "    return d\n",
    "\n",
    "for col in tqdm(json_cols + ['belongs_to_collection']) :\n",
    "    train[col] = train[col].apply(lambda x : get_dictionary(x))\n",
    "    test[col] = test[col].apply(lambda x : get_dictionary(x))\n",
    "    \n",
    "def get_json_dict(df) :\n",
    "    global json_cols\n",
    "    result = dict()\n",
    "    for e_col in json_cols :\n",
    "        d = dict()\n",
    "        rows = df[e_col].values\n",
    "        for row in rows :\n",
    "            if row is None : continue\n",
    "            for i in row :\n",
    "                if i['name'] not in d :\n",
    "                    d[i['name']] = 0\n",
    "                d[i['name']] += 1\n",
    "        result[e_col] = d\n",
    "    return result\n",
    "\n",
    "train_dict = get_json_dict(train)\n",
    "test_dict = get_json_dict(test)\n",
    "\n",
    "# remove cateogry with bias and low frequency\n",
    "for col in json_cols :\n",
    "    \n",
    "    remove = []\n",
    "    train_id = set(list(train_dict[col].keys()))\n",
    "    test_id = set(list(test_dict[col].keys()))   \n",
    "    \n",
    "    remove += list(train_id - test_id) + list(test_id - train_id)\n",
    "    for i in train_id.union(test_id) - set(remove) :\n",
    "        if train_dict[col][i] < 10 or i == '' :\n",
    "            remove += [i]\n",
    "            \n",
    "    for i in remove :\n",
    "        if i in train_dict[col] :\n",
    "            del train_dict[col][i]\n",
    "        if i in test_dict[col] :\n",
    "            del test_dict[col][i]\n",
    "\n",
    "all_data = prepare(pd.concat([train, test]).reset_index(drop = True))\n",
    "train = all_data.loc[:train.shape[0] - 1,:]\n",
    "test = all_data.loc[train.shape[0]:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "random_seed = 2019\n",
    "k = 15\n",
    "fold = list(KFold(k, shuffle = True, random_state = random_seed).split(train))\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoosting\n",
    "import xgboost as xgb\n",
    "\n",
    "def xgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "    \n",
    "    params = {'objective': 'reg:linear', \n",
    "              'eta': 0.01, \n",
    "              'max_depth': 6, \n",
    "              'subsample': 0.6, \n",
    "              'colsample_bytree': 0.7,  \n",
    "              'eval_metric': 'rmse', \n",
    "              'seed': random_seed, \n",
    "              'silent': True,\n",
    "    }\n",
    "    \n",
    "    record = dict()\n",
    "    model = xgb.train(params\n",
    "                      , xgb.DMatrix(trn_x, trn_y)\n",
    "                      , 100000\n",
    "                      , [(xgb.DMatrix(trn_x, trn_y), 'train'), (xgb.DMatrix(val_x, val_y), 'valid')]\n",
    "                      , verbose_eval=verbose\n",
    "                      , early_stopping_rounds=500\n",
    "                      , callbacks = [xgb.callback.record_evaluation(record)])\n",
    "    best_idx = np.argmin(np.array(record['valid']['rmse']))\n",
    "\n",
    "    val_pred = model.predict(xgb.DMatrix(val_x), ntree_limit=model.best_ntree_limit)\n",
    "    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "    return {'val':val_pred, 'test':test_pred, 'error':record['valid']['rmse'][best_idx], 'importance':[i for k, i in model.get_score().items()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "def lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "\n",
    "    params = {'objective':'regression',\n",
    "         'num_leaves' : 30,\n",
    "         'min_data_in_leaf' : 20,\n",
    "         'max_depth' : 9,\n",
    "         'learning_rate': 0.004,\n",
    "         #'min_child_samples':100,\n",
    "         'feature_fraction':0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         'lambda_l1': 0.2,\n",
    "         \"bagging_seed\": random_seed,\n",
    "         \"metric\": 'rmse',\n",
    "         #'subsample':.8, \n",
    "          #'colsample_bytree':.9,\n",
    "         \"random_state\" : random_seed,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "    record = dict()\n",
    "    model = lgb.train(params\n",
    "                      , lgb.Dataset(trn_x, trn_y)\n",
    "                      , num_boost_round = 100000\n",
    "                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n",
    "                      , verbose_eval = verbose\n",
    "                      , early_stopping_rounds = 500\n",
    "                      , callbacks = [lgb.record_evaluation(record)]\n",
    "                     )\n",
    "    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n",
    "\n",
    "    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n",
    "    test_pred = model.predict(test, num_iteration = model.best_iteration)\n",
    "    \n",
    "    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAT Boost\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=100000,\n",
    "                                 learning_rate=0.004,\n",
    "                                 depth=5,\n",
    "                                 eval_metric='RMSE',\n",
    "                                 colsample_bylevel=0.8,\n",
    "                                 random_seed = random_seed,\n",
    "                                 bagging_temperature = 0.2,\n",
    "                                 metric_period = None,\n",
    "                                 early_stopping_rounds=200\n",
    "                                )\n",
    "    model.fit(trn_x, trn_y,\n",
    "                 eval_set=(val_x, val_y),\n",
    "                 use_best_model=True,\n",
    "                 verbose=False)\n",
    "    \n",
    "    val_pred = model.predict(val_x)\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    return {'val':val_pred, \n",
    "            'test':test_pred, \n",
    "            'error':model.get_best_score()['validation_0']['RMSE']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold.    RMSE\n",
      "xgb model. 2.46543 (0m)\n",
      "lgb model. 2.49461 (0m)\n",
      "cat model. 2.37074 (3m)\n",
      "---------------------------\n",
      "avg   err. 2.44359\n",
      "blend err. 10.29801\n",
      "\n",
      "2 fold.    RMSE\n",
      "xgb model. 2.22245 (0m)\n",
      "lgb model. 2.16736 (0m)\n",
      "cat model. 2.20200 (2m)\n",
      "---------------------------\n",
      "avg   err. 2.19727\n",
      "blend err. 10.21216\n",
      "\n",
      "3 fold.    RMSE\n",
      "xgb model. 1.66980 (1m)\n",
      "lgb model. 1.71273 (0m)\n",
      "cat model. 1.73707 (2m)\n",
      "---------------------------\n",
      "avg   err. 1.70653\n",
      "blend err. 10.54163\n",
      "\n",
      "4 fold.    RMSE\n",
      "xgb model. 2.26847 (1m)\n",
      "lgb model. 2.29511 (0m)\n",
      "cat model. 2.31440 (3m)\n",
      "---------------------------\n",
      "avg   err. 2.29266\n",
      "blend err. 10.13756\n",
      "\n",
      "5 fold.    RMSE\n",
      "xgb model. 2.11120 (0m)\n",
      "lgb model. 2.09945 (0m)\n",
      "cat model. 2.06133 (6m)\n",
      "---------------------------\n",
      "avg   err. 2.09066\n",
      "blend err. 10.45376\n",
      "\n",
      "6 fold.    RMSE\n",
      "xgb model. 1.85562 (0m)\n",
      "lgb model. 1.83571 (0m)\n",
      "cat model. 1.82303 (2m)\n",
      "---------------------------\n",
      "avg   err. 1.83812\n",
      "blend err. 10.26184\n",
      "\n",
      "7 fold.    RMSE\n",
      "xgb model. 2.16297 (1m)\n",
      "lgb model. 2.19175 (0m)\n",
      "cat model. 2.17926 (10m)\n",
      "---------------------------\n",
      "avg   err. 2.17799\n",
      "blend err. 10.31097\n",
      "\n",
      "8 fold.    RMSE\n",
      "xgb model. 2.48721 (0m)\n",
      "lgb model. 2.48746 (0m)\n",
      "cat model. 2.53150 (1m)\n",
      "---------------------------\n",
      "avg   err. 2.50206\n",
      "blend err. 10.23421\n",
      "\n",
      "9 fold.    RMSE\n",
      "xgb model. 2.11747 (0m)\n",
      "lgb model. 2.10369 (0m)\n",
      "cat model. 2.07923 (3m)\n",
      "---------------------------\n",
      "avg   err. 2.10013\n",
      "blend err. 10.51126\n",
      "\n",
      "10 fold.    RMSE\n",
      "xgb model. 2.04314 (1m)\n",
      "lgb model. 2.06715 (0m)\n",
      "cat model. 2.04712 (3m)\n",
      "---------------------------\n",
      "avg   err. 2.05247\n",
      "blend err. 10.43864\n",
      "\n",
      "11 fold.    RMSE\n",
      "xgb model. 2.40558 (1m)\n",
      "lgb model. 2.42307 (0m)\n",
      "cat model. 2.42196 (2m)\n",
      "---------------------------\n",
      "avg   err. 2.41687\n",
      "blend err. 10.57614\n",
      "\n",
      "12 fold.    RMSE\n",
      "xgb model. 2.32098 (0m)\n",
      "lgb model. 2.33132 (0m)\n",
      "cat model. 2.38076 (1m)\n",
      "---------------------------\n",
      "avg   err. 2.34435\n",
      "blend err. 10.06224\n",
      "\n",
      "13 fold.    RMSE\n",
      "xgb model. 2.33791 (1m)\n",
      "lgb model. 2.34914 (0m)\n",
      "cat model. 2.21972 (4m)\n",
      "---------------------------\n",
      "avg   err. 2.30226\n",
      "blend err. 10.18629\n",
      "\n",
      "14 fold.    RMSE\n",
      "xgb model. 2.04500 (1m)\n",
      "lgb model. 1.98772 (0m)\n",
      "cat model. 2.06396 (1m)\n",
      "---------------------------\n",
      "avg   err. 2.03223\n",
      "blend err. 10.44193\n",
      "\n",
      "15 fold.    RMSE\n",
      "xgb model. 2.34664 (0m)\n",
      "lgb model. 2.35278 (0m)\n",
      "cat model. 2.35924 (1m)\n",
      "---------------------------\n",
      "avg   err. 2.35289\n",
      "blend err. 10.23958\n",
      "\n",
      "fianl avg   err. 2.19000524546429\n",
      "fianl blend err. 10.328180671013754\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "val_pred = np.zeros(train.shape[0])\n",
    "test_pred = np.zeros(test.shape[0])\n",
    "final_err = 0\n",
    "verbose = False\n",
    "\n",
    "for i, (trn, val) in enumerate(fold) :\n",
    "    print(i+1, \"fold.    RMSE\")\n",
    "    \n",
    "    trn_x = train.loc[trn, :]\n",
    "    trn_y = y[trn]\n",
    "    val_x = train.loc[val, :]\n",
    "    val_y = y[val]\n",
    "    \n",
    "    fold_val_pred = []\n",
    "    fold_test_pred = []\n",
    "    fold_err = []\n",
    "    \n",
    "    #\"\"\" xgboost\n",
    "    start = datetime.now()\n",
    "    result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val']*0.2)\n",
    "    fold_test_pred.append(result['test']*0.2)\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    #\"\"\"\n",
    "    \n",
    "    #\"\"\" lightgbm\n",
    "    start = datetime.now()\n",
    "    result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val']*0.4)\n",
    "    fold_test_pred.append(result['test']*0.4)\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    #\"\"\"\n",
    "    \n",
    "    #\"\"\" catboost model\n",
    "    start = datetime.now()\n",
    "    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n",
    "    fold_val_pred.append(result['val']*0.4)\n",
    "    fold_test_pred.append(result['test']*0.4)\n",
    "    fold_err.append(result['error'])\n",
    "    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n",
    "    #\"\"\"\n",
    "    \n",
    "    # mix result of multiple models\n",
    "    val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n",
    "    #print(fold_test_pred)\n",
    "    #print(fold_test_pred.shape)\n",
    "    #print(fold_test_pred.columns)\n",
    "    test_pred += np.mean(np.array(fold_test_pred), axis = 0) / k\n",
    "    final_err += (sum(fold_err) / len(fold_err)) / k\n",
    "    \n",
    "    print(\"---------------------------\")\n",
    "    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n",
    "    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "print(\"fianl avg   err.\", final_err)\n",
    "print(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}